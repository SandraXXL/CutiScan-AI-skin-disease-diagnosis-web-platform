{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define directories\n",
    "train_dir = '/Users/sandrachee/Desktop/new_dataset/training'\n",
    "test_dir = '/Users/sandrachee/Desktop/new_dataset/testing'\n",
    "image_size = (299, 299)\n",
    "batch_size = 68\n",
    "num_classes = len(os.listdir(train_dir))  \n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7070 images belonging to 12 classes.\n",
      "Found 676 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,  # Shuffle the training data\n",
    "    seed=42  # Set seed for reproducibility\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # No need to shuffle the testing data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load InceptionV3 base model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top of InceptionV3\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Adding Dropout layer\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers from base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=5,\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 6s/step - accuracy: 0.3977 - loss: 1.8889 - val_accuracy: 0.7974 - val_loss: 0.8159\n",
      "Epoch 2/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 6s/step - accuracy: 0.7590 - loss: 0.8258 - val_accuracy: 0.8301 - val_loss: 0.5599\n",
      "Epoch 3/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 6s/step - accuracy: 0.8247 - loss: 0.5975 - val_accuracy: 0.8627 - val_loss: 0.4728\n",
      "Epoch 4/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 6s/step - accuracy: 0.8525 - loss: 0.4937 - val_accuracy: 0.8775 - val_loss: 0.4100\n",
      "Epoch 5/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 6s/step - accuracy: 0.8647 - loss: 0.4277 - val_accuracy: 0.9003 - val_loss: 0.3777\n",
      "Epoch 6/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 6s/step - accuracy: 0.8834 - loss: 0.3872 - val_accuracy: 0.9020 - val_loss: 0.3399\n",
      "Epoch 7/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 6s/step - accuracy: 0.8882 - loss: 0.3684 - val_accuracy: 0.9020 - val_loss: 0.3182\n",
      "Epoch 8/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 6s/step - accuracy: 0.9019 - loss: 0.3162 - val_accuracy: 0.8889 - val_loss: 0.3131\n",
      "Epoch 9/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 6s/step - accuracy: 0.9126 - loss: 0.2912 - val_accuracy: 0.8938 - val_loss: 0.2968\n",
      "Epoch 10/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 6s/step - accuracy: 0.9109 - loss: 0.2815 - val_accuracy: 0.9232 - val_loss: 0.2700\n",
      "Epoch 11/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 6s/step - accuracy: 0.9120 - loss: 0.2591 - val_accuracy: 0.9101 - val_loss: 0.2790\n",
      "Epoch 12/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 6s/step - accuracy: 0.9286 - loss: 0.2364 - val_accuracy: 0.9003 - val_loss: 0.2773\n",
      "Epoch 13/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 6s/step - accuracy: 0.9299 - loss: 0.2233 - val_accuracy: 0.9248 - val_loss: 0.2465\n",
      "Epoch 14/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 6s/step - accuracy: 0.9315 - loss: 0.2230 - val_accuracy: 0.9167 - val_loss: 0.2361\n",
      "Epoch 15/15\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 6s/step - accuracy: 0.9340 - loss: 0.2087 - val_accuracy: 0.9232 - val_loss: 0.2325\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 15\n",
    "steps_per_epoch = train_generator.samples // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=1,  \n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_generator.samples // batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on validation set...\n",
      "Found 676 images belonging to 12 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6s/step\n",
      "\n",
      "Validation Metrics:\n",
      "Accuracy: 0.9127\n",
      "Precision: 0.9168\n",
      "Recall: 0.9127\n",
      "F1-score: 0.9121\n",
      "\n",
      "Classification Report:\n",
      "acne: {'precision': 0.9487179487179487, 'recall': 0.9024390243902439, 'f1-score': 0.9249999999999999, 'support': 82}\n",
      "alopecia: {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 76}\n",
      "athlete_foot: {'precision': 0.8441558441558441, 'recall': 0.9285714285714286, 'f1-score': 0.8843537414965986, 'support': 70}\n",
      "cellulitis: {'precision': 0.9178082191780822, 'recall': 0.9305555555555556, 'f1-score': 0.9241379310344828, 'support': 72}\n",
      "chickenpox: {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 66}\n",
      "cutaneous_larva_migrans: {'precision': 0.8297872340425532, 'recall': 0.8863636363636364, 'f1-score': 0.8571428571428571, 'support': 44}\n",
      "impetigo: {'precision': 0.9523809523809523, 'recall': 1.0, 'f1-score': 0.975609756097561, 'support': 40}\n",
      "nail_fungus: {'precision': 0.803030303030303, 'recall': 0.8548387096774194, 'f1-score': 0.828125, 'support': 62}\n",
      "ringworm: {'precision': 0.7567567567567568, 'recall': 0.9333333333333333, 'f1-score': 0.835820895522388, 'support': 30}\n",
      "shingles: {'precision': 0.8571428571428571, 'recall': 0.6, 'f1-score': 0.7058823529411764, 'support': 10}\n",
      "urticaria: {'precision': 0.8666666666666667, 'recall': 0.5909090909090909, 'f1-score': 0.7027027027027029, 'support': 22}\n",
      "vitiligo: {'precision': 1.0, 'recall': 0.8823529411764706, 'f1-score': 0.9375, 'support': 102}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[74  0  0  0  2  3  0  0  1  0  2  0]\n",
      " [ 0 76  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 65  4  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  1 67  0  0  0  3  1  0  0  0]\n",
      " [ 0  0  0  0 66  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  2  0 39  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0 40  0  0  0  0  0]\n",
      " [ 0  0  7  0  0  2  0 53  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  1 28  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  4  6  0  0]\n",
      " [ 4  0  0  0  0  2  0  0  3  0 13  0]\n",
      " [ 0  0  1  0  0  1  1  9  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting on validation set\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "print(\"Predicting on validation set...\")\n",
    "\n",
    "# Generate predictions for the validation set\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order of predictions consistent for evaluation\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(validation_generator, steps=len(validation_generator), verbose=1)\n",
    "\n",
    "# Convert predictions into class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = validation_generator.classes\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted', zero_division=0)\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted', zero_division=0)\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Generate and print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels, output_dict=True, zero_division=0)\n",
    "for label in class_labels:\n",
    "    if label not in report:\n",
    "        report[label] = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0}\n",
    "    print(f\"{label}: {report[label]}\")\n",
    "\n",
    "# Generate and print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_classes, predicted_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img_path = '/Users/sandrachee/Desktop/urt.jpg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.  # Normalize pixel values\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Interpret predictions\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class_name = class_labels[predicted_class_index]\n",
    "confidence = predictions[0][predicted_class_index]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class_name}\")\n",
    "print(f\"Confidence: {confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_new.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
